# AWARDS
<p align="center">
<img src="https://github.com/MSDEOKAR/Emotion-Detection-Using-Multi-Modal-AI/assets/109652802/fa274120-1f52-472e-9733-5f2f2ebb5d97" alt="Certificate" width="900" height="600" ali>
</p>







# Multimodal Emotion Recognition Project

Emotional expression is a crucial element in human social and daily communication activities. Emotion recognition, a technology leveraging computer science, is designed to identify the emotions of recognized objects. While single-modal emotion recognition has been the predominant method, there is a growing interest in multimodal emotion recognition.

## Project Overview

This project delves into the intricate tapestry of human communication, combining text, video, and audio to unveil the hidden landscape of emotions. By harnessing the power of multimodal AI, the goal is to paint a richer portrait of human sentiment. This involves capturing the nuances of tone, gesture, and the subtle tremors in the voice. Imagine a world where machines not only decipher the meaning of our words but also empathize with the feelings that color them.

## The Multimodal EmotionLines Dataset (MELD)

Until now, there has been a lack of largescale multimodal multi-party emotional conversational databases containing more than two speakers per dialogue. To address this gap, we introduce the Multimodal EmotionLines Dataset (MELD), which is an extension and enhancement of EmotionLines.

MELD comprises approximately 13,000 utterances from 1,433 dialogues from the TV series Friends. Each utterance is annotated with emotion and sentiment labels, encompassing audio, visual, and textual modalities. The dataset is designed to facilitate research in emotion recognition, particularly in the context of conversations.

[MELD Dataset Download Link](https://www.kaggle.com/datasets/zaber666/meld-dataset)

## Research Contribution

We propose several strong multimodal baselines, highlighting the importance of contextual and multimodal information for accurate emotion recognition in conversations. Our project aims to advance the field of emotion recognition by providing a comprehensive dataset and robust baselines for further research and development.

## Results
![Tetxt](https://github.com/MSDEOKAR/Emotion-Detection-Using-Multi-Modal-AI/assets/109652802/43754c25-58b9-4616-bd93-263550e0c7ef)
![Video](https://github.com/MSDEOKAR/Emotion-Detection-Using-Multi-Modal-AI/assets/109652802/e9c218a7-66c2-451e-aa58-8746218d1ca9)
![Audio](https://github.com/MSDEOKAR/Emotion-Detection-Using-Multi-Modal-AI/assets/109652802/e2f4a1b9-665e-43d5-800d-8d58bcdca6d7)


### Report
[View PDF](https://app.luminpdf.com/viewer/65b384660fd90ecddd8f3fa4)
